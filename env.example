# Backend
UVICORN_IP=0.0.0.0
UVICORN_PORT=8000
# Estoy usando OpenAI para un LLM con router usar https://requesty.ai/v1 
LLM_ROUTER_URL="https://api.openai.com/v1"
LLM_ROUTER_API_KEY=<your-api-key>
# Change this to an OpenAI model if not using requesty.ai
LLM_MODEL="o4-mini" 
EMBEDDING_MODEL="text-embedding-3-small"
OPENAI_API_KEY=<your-openai-api-key>
FRONTEND_URL=http://localhost:5173

# Postgres
POSTGRES_SERVER=localhost
POSTGRES_PORT=5432
POSTGRES_DB=pgdb
POSTGRES_USER=pguser
POSTGRES_PASSWORD=docker

# Redis and Rate Limiting
REDIS_URL=redis://localhost:6379
GLOBAL_RATE_LIMIT=1000/hour
CHAT_RATE_LIMIT=30/minute

# Frontend
VITE_BACKEND_URL=http://localhost:8000 
